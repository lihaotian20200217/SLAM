/*
    Pnp+g2o_BundleAdjustment
    单目相机经过对极几何初始化(八点法，单应矩阵)求解一些3D点后
    或者双目相机，深度相机可以直接得到三维点不需要初始化得到最开始的三维点
    那么可以使用3D-2D点对参与计算，方法有：直接线性变换DLT n点透视问题PnP 最小二乘最小化重投影误差 
    【1】PnP 直接线性变换DLT 6个 3D - 2D 点对
    2D点 s1 * (u,v,1) = T * (X,Y,Z,1) = T * P 齐次坐标 T = [R t] 为 3 * 4的矩阵
    T = [t1 t2 t3 t4; t5 t6 t7 t8; t9 t10 t11 t12] = [T1; T2; T3]
    可得到 u = T1*P/(T3*P) v = T2*P/(T3*P)
    可得 T3*P*u - T1*P = 0 以及 T3*P*v - T2*P = 0 每个3D-2D点对可提供两个约束
    T有 12个变量 至少需要6个3D-2D点对
    求解的T的左大半部分不一定满足旋转矩阵R的约束关系，得到T后需要使用QR分解 使得得到的T满足SE3
    相当于对求出的T重新映射到SE3流行上
    
    G2O使用
    顶点1 相机位姿-变换T 类型为 g2o::VertexSE3Expmap 李代数位姿 
    顶点2 相机1特征点由深度得到的空间三维点P类型为 g2o::VertexSBAPointXYZ
    边    图像1由深度得到的三维点经过位姿T重投影在图像2上与图像2上相对应的特征点的量测位置的坐标误差 g2o::EdgeProjectXYZ2UV
    以上类型为g2o已经定义好的类型在 g2o/types/sba/types_six_dof_expmap.h
    // g2o::VertexSE3Expmap 李代数位姿
    class G2O_TYPES_SBA_API VertexSE3Expmap : public BaseVertex<6,SE3Quat>{
        // 第一个参数 6 表示6维的优化变量 类型为 SE3Quat四元数+位移的表示
    public:
        EIGEN_MAKE_ALIGNED_OPERATOR_NEW

        VertexSE3Expmap();

        bool read(std::istream& is);
        bool write(std::ostream& os) const;

        virtual void setToOriginImpl() {
            _estimate = SE3Quat();
        }

        virtual void oplusImpl(const double* update_) {
            Eigen::Map<const Vector6d> update(update_);
            setEstimate(SE3Quat::exp(update)*estimate());
        }
    };

//g2o::EdgeProjectXYZ2UV 投影方程边 二元边
class G2O_TYPES_SBA_API EdgeProjectXYZ2UV : public BaseBinaryEdge<2,Vector2D,VertexSBAPointXYZ,VertexSE3Expmap>{
    // 观测维度为2 空间点的像素坐标类型Vector2D连接的两个顶点 6维位姿 和 三维点
public:
    EIGEN_MAKE_ALIGNED_OPERATOR_NEW;
    EdgeProjectXYZ2UV();
    bool read(std::istream& is);
    bool write(std::ostream& os) const;

    void computeError() {
        const VertexSE3Expmap* v1 = static_cast<const VertexSE3Expmap*>(_vertices[1]);//6维位姿 顶点
        const VertexSBAPointXYZ* v2 = static_cast<const VertexSBAPointXYZ*>(_vertices[0]);//三维点 顶点
        const CameraParameters* cam = static_cast<const CameraParameters*>(parameter(0));
        Vector2D obs(_measurement); // 观测值
        _error = obs - cam->cam_map(v1->estimate().map(v2->estimate()));
        // 位姿对三维点映射得到重投影后的像素点
        // 误差 = 观测值 - 重投影后的像素点
    }

    virtual void linearizeOplus(); // 雅克比矩阵 优化求解析
    CameraParameters* _cam;
}

void EdgeProjectXYZ2UV::linearizeOplus() {
    VertexSE3Expmap* vj = static_cast<VertexSE3Expmap*>(_vertices[1]);//6维位姿 顶点
    SE3Quat T(vj->estimate()); // 转化成变换矩阵形式
    VertexSBAPointXYZ* vi = static_cast<VertexSBAPointXYZ*>(_vertices[0]); // 三维点 顶点
    Vector3D xyz = vi->estimate(); // 三维点
    Vector3D xyz_trans = T.map(xyz); 

    
}

*/

// 实现
#include <iostream>
// opencv
#include <opencv2/core/core.hpp>
#include <opencv2/features2d/features2d.hpp>// 2D特征
#include <opencv2/highgui/highgui.hpp>
#include <opencv2/calib3d/calib3d.hpp>
// Eigen3
#include <Eigen/Core>
#include <Eigen/Geometry>
// G2O
#include <g2o/core/base_vertex.h> // 顶点
#include <g2o/core/base_unary_edge.h> // 边
#include <g2o/core/block_solver.h> // 矩阵块 分解 求解器 矩阵空间 映射 分解
#include <g2o/core/optimization_algorithm_levenberg.h>// LM
#include <g2o/solvers/csparse/linear_solver_csparse.h> // 空间曲面 线性优化
#include <g2o/types/sba/types_six_dof_expmap.h>//定义好的顶点类型 6维度 优化变量 例如 相机 位姿 3维空间点 投影边 

#include <chrono>

using namespace std;
using namespace cv;

// 特征匹配 计算匹配点对
void find_feature_matches (const Mat& img_1, const Mat& img_2, // & 为引用直接使用参数本身不进行复制节省时间 
    std::vector<KeyPoint>& keypoints_1, std::vector<KeyPoint>& keypoints_2,
    std::vector<DMatch>& matches); // 描述子

// 像素坐标转相机归一化坐标
Point2d pixel2cam (const Point2d& p, const Mat& K);

// g2o_BundleAdjustment 优化 计算旋转和平移
// 使用 3D-2D点对
void bundleAdjustment (
    const vector<Point3f> points_3d, //两幅图像特征点对中其一点根据深度信息得到的世界坐标系下的3D点
    const vector<Point2f> points_2d, //特征点对中的另一个为2D点
    const Mat& K,
    Mat& R, Mat& t
);

int main (int argc, char** argv )
{
    if ( argc != 5) // 命令行参数 img1 img2 depth1 depth2
    {
        cout << "  ";
        return 1;
    }
    // 读取图像
    Mat img_1 = imread ( argv[1], CV_LOAD_IMAGE_COLOR );
    Mat img_2 = imread ( argv[2], CV_LOAD_IMAGE_COLOR );

    // 找到 两幅图像中的特征匹配点对
    vector<KeyPoint> keypoints_1, keypoints_2; // 关键点
    vector<DMatch> matches; // 特征点匹配对
    find_feature_matches (img_1, img_2, keypoints_1, keypoints_2, matches);
    cout << "一共找到了" << matches.size() << "组匹配点" << endl;

    // 建立3D点
    // 相机内参数
    //   [fx 0 cx
    //    0  fy cy
    //    0  0  1]
    Mat d1 = imread(argv[3], CV_LOAD_IMAGE_UNCHANGED ); // 深度图为16位无符号数，单通道图像
    Mat K = ( Mat_<double> (3,3) << 520.9, 0, 325.1, 0, 521.0, 249.7, 0, 0, 1); // 相机内参
    vector<Point3f> pts_3d; // 3D点 第一幅图像中的特征点对应的3维点
    vector<Point2f> pts_2d; // 2D点 第二幅图像中的特征点
    for ( DMatch m : matches )
    {
        ushort d = d1.ptr<unsigned short> (int ( keypoints_1[m.queryIdx].pt.y)) [ int ( keypoints_1[m.queryIdx].pt.x) ]; // 匹配点对 对应的深度
        if ( d == 0 ) // bad depth1
            continue;
        float dd = d/1000.0 // 深度单位为 mm 所以转化为 m 除去尺度因子
        Point2d p1 = pixel2cam ( keypoints_1[m.queryIdex].pt, K); // 像素坐标转相机下归一化坐标 x,y,1
        pts_3d.push_back(Point3f(p1.x*dd,p1.y*dd,dd)); // 3D点 第一幅图像中的特征点对应的3维点
        pts_2d.push_back(keypoints_2[m.trainIdx].pt);

    }
}