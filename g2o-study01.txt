/*
    Pnp+g2o_BundleAdjustment
    单目相机经过对极几何初始化(八点法，单应矩阵)求解一些3D点后
    或者双目相机，深度相机可以直接得到三维点不需要初始化得到最开始的三维点
    那么可以使用3D-2D点对参与计算，方法有：直接线性变换DLT n点透视问题PnP 最小二乘最小化重投影误差 
    【1】PnP 直接线性变换DLT 6个 3D - 2D 点对
    2D点 s1 * (u,v,1) = T * (X,Y,Z,1) = T * P 齐次坐标 T = [R t] 为 3 * 4的矩阵
    T = [t1 t2 t3 t4; t5 t6 t7 t8; t9 t10 t11 t12] = [T1; T2; T3]
    可得到 u = T1*P/(T3*P) v = T2*P/(T3*P)
    可得 T3*P*u - T1*P = 0 以及 T3*P*v - T2*P = 0 每个3D-2D点对可提供两个约束
    T有 12个变量 至少需要6个3D-2D点对
    求解的T的左大半部分不一定满足旋转矩阵R的约束关系，得到T后需要使用QR分解 使得得到的T满足SE3
    相当于对求出的T重新映射到SE3流行上
    
    G2O使用
    顶点1 相机位姿-变换T 类型为 g2o::VertexSE3Expmap 李代数位姿 
    顶点2 相机1特征点由深度得到的空间三维点P类型为 g2o::VertexSBAPointXYZ
    边    图像1由深度得到的三维点经过位姿T重投影在图像2上与图像2上相对应的特征点的量测位置的坐标误差 g2o::EdgeProjectXYZ2UV
    以上类型为g2o已经定义好的类型在 g2o/types/sba/types_six_dof_expmap.h
    // g2o::VertexSE3Expmap 李代数位姿
    class G2O_TYPES_SBA_API VertexSE3Expmap : public BaseVertex<6,SE3Quat>{
        // 第一个参数 6 表示6维的优化变量 类型为 SE3Quat四元数+位移的表示
    public:
        EIGEN_MAKE_ALIGNED_OPERATOR_NEW

        VertexSE3Expmap();

        bool read(std::istream& is);
        bool write(std::ostream& os) const;

        virtual void setToOriginImpl() {
            _estimate = SE3Quat();
        }

        virtual void oplusImpl(const double* update_) {
            Eigen::Map<const Vector6d> update(update_);
            setEstimate(SE3Quat::exp(update)*estimate());
        }
    };

//g2o::EdgeProjectXYZ2UV 投影方程边 二元边
class G2O_TYPES_SBA_API EdgeProjectXYZ2UV : public BaseBinaryEdge<2,Vector2D,VertexSBAPointXYZ,VertexSE3Expmap>{
    // 观测维度为2 空间点的像素坐标类型Vector2D连接的两个顶点 6维位姿 和 三维点
public:
    EIGEN_MAKE_ALIGNED_OPERATOR_NEW;
    EdgeProjectXYZ2UV();
    bool read(std::istream& is);
    bool write(std::ostream& os) const;

    void computeError() {
        const VertexSE3Expmap* v1 = static_cast<const VertexSE3Expmap*>(_vertices[1]);//6维位姿 顶点
        const VertexSBAPointXYZ* v2 = static_cast<const VertexSBAPointXYZ*>(_vertices[0]);//三维点 顶点
        const CameraParameters* cam = static_cast<const CameraParameters*>(parameter(0));
        Vector2D obs(_measurement); // 观测值
        _error = obs - cam->cam_map(v1->estimate().map(v2->estimate()));
        // 位姿对三维点映射得到重投影后的像素点
        // 误差 = 观测值 - 重投影后的像素点
    }

    virtual void linearizeOplus(); // 雅克比矩阵 优化求解析
    CameraParameters* _cam;
}

void EdgeProjectXYZ2UV::linearizeOplus() {
    VertexSE3Expmap* vj = static_cast<VertexSE3Expmap*>(_vertices[1]);//6维位姿 顶点
    SE3Quat T(vj->estimate()); // 转化成变换矩阵形式
    VertexSBAPointXYZ* vi = static_cast<VertexSBAPointXYZ*>(_vertices[0]); // 三维点 顶点
    Vector3D xyz = vi->estimate(); // 三维点
    Vector3D xyz_trans = T.map(xyz); 

    
}

*/

// 实现
#include <iostream>
// opencv
#include <opencv2/core/core.hpp>
#include <opencv2/features2d/features2d.hpp>// 2D特征
#include <opencv2/highgui/highgui.hpp>
#include <opencv2/calib3d/calib3d.hpp>
// Eigen3
#include <Eigen/Core>
#include <Eigen/Geometry>
// G2O
#include <g2o/core/base_vertex.h> // 顶点
#include <g2o/core/base_unary_edge.h> // 边
#include <g2o/core/block_solver.h> // 矩阵块 分解 求解器 矩阵空间 映射 分解
#include <g2o/core/optimization_algorithm_levenberg.h>// LM
#include <g2o/solvers/csparse/linear_solver_csparse.h> // 空间曲面 线性优化
#include <g2o/types/sba/types_six_dof_expmap.h>//定义好的顶点类型 6维度 优化变量 例如 相机 位姿 3维空间点 投影边 

#include <chrono>

using namespace std;
using namespace cv;

// 特征匹配 计算匹配点对
void find_feature_matches (const Mat& img_1, const Mat& img_2, // & 为引用直接使用参数本身不进行复制节省时间 
    std::vector<KeyPoint>& keypoints_1, std::vector<KeyPoint>& keypoints_2,
    std::vector<DMatch>& matches); // 描述子

// 像素坐标转相机归一化坐标
Point2d pixel2cam (const Point2d& p, const Mat& K);

// g2o_BundleAdjustment 优化 计算旋转和平移
// 使用 3D-2D点对
void bundleAdjustment (
    const vector<Point3f> points_3d, //两幅图像特征点对中其一点根据深度信息得到的世界坐标系下的3D点
    const vector<Point2f> points_2d, //特征点对中的另一个为2D点
    const Mat& K,
    Mat& R, Mat& t
);

int main (int argc, char** argv )
{
    if ( argc != 5) // 命令行参数 img1 img2 depth1 depth2
    {
        cout << "  ";
        return 1;
    }
    // 读取图像
    Mat img_1 = imread ( argv[1], CV_LOAD_IMAGE_COLOR );
    Mat img_2 = imread ( argv[2], CV_LOAD_IMAGE_COLOR );

    // 找到 两幅图像中的特征匹配点对
    vector<KeyPoint> keypoints_1, keypoints_2; // 关键点
    vector<DMatch> matches; // 特征点匹配对
    find_feature_matches (img_1, img_2, keypoints_1, keypoints_2, matches);
    cout << "一共找到了" << matches.size() << "组匹配点" << endl;

    // 建立3D点
    // 相机内参数
    //   [fx 0 cx
    //    0  fy cy
    //    0  0  1]
    Mat d1 = imread(argv[3], CV_LOAD_IMAGE_UNCHANGED ); // 深度图为16位无符号数，单通道图像
    Mat K = ( Mat_<double> (3,3) << 520.9, 0, 325.1, 0, 521.0, 249.7, 0, 0, 1); // 相机内参
    vector<Point3f> pts_3d; // 3D点 第一幅图像中的特征点对应的3维点
    vector<Point2f> pts_2d; // 2D点 第二幅图像中的特征点
    for ( DMatch m : matches )
    {
        ushort d = d1.ptr<unsigned short> (int ( keypoints_1[m.queryIdx].pt.y)) [ int ( keypoints_1[m.queryIdx].pt.x) ]; // 匹配点对 对应的深度
        if ( d == 0 ) // bad depth1
            continue;
        float dd = d/1000.0 // 深度单位为 mm 所以转化为 m 除去尺度因子
        Point2d p1 = pixel2cam ( keypoints_1[m.queryIdex].pt, K); // 像素坐标转相机下归一化坐标 x,y,1
        pts_3d.push_back(Point3f(p1.x*dd,p1.y*dd,dd)); // 3D点 第一幅图像中的特征点对应的3维点
        pts_2d.push_back(keypoints_2[m.trainIdx].pt);// 2D点 第二幅图像中的特征点
    }

    cout << "3d-2d 点对数 : "<<pts_3d.size() << endl;
    // 利用 PnP 求解初始解
    Mat r, t; // 得到初始旋转向量r和平移量t
    solvePnP(pts_3d,pts_2d,K,Mat(),r,t,false);// 调用OpenCV的PnP求解
    Mat R;
    cv::Rodrigues(r,R);// r为旋转量形式,用Rodrigues公式转换为矩阵 罗德里格斯公式 将旋转向量转旋转矩阵
    cout << "初始旋转矩阵 R=" << endl << R << endl;
    cout << "初始平移向量 t=" << endl << t << endl;

    cout << "使用 bundle adjustment优化算法 对R和T进行优化：" << endl;
    bundleAdjustment(pts_3d,pts_2d,K,R,t);
}

// 特征匹配 计算匹配点对 函数
void find_feature_matches(const Mat& img_1, const Mat& img2, std::vector<KeyPoint>& keypoints_1,std::vector<KeyPoint>& keypoints_2,std::vector<DMatch>& matches)
{
    //--------------------第0步：初始化-------------------
    Mat descriptors_1, descriptors_2; // 描述子
    Ptr<FeatureDetector> detector = ORB::create();//特征点检测器
    Prt<DescriptorExtractor> descriptor = ORB::create();
    // opencv2 特征点检测器 描述子生成器 用法
    // Ptr<FeatureDetector> detector = FeatureDetector::;create("ORB");
    // Ptr<DescriptorExtractor> descriptor = DescriptorExtractor::create("ORB");
    Ptr<DescriptorExtractor> matcher = DescriptorMatcher::create("BruteForce-Hamming"); // 二进制描述子

    // --第一步：检测 Oriented FAST 角点位置
    detector->detect(img_1,keypoints_1);
    detector->detect(img_2,keypoints_2);

    // --第二步：根据角点位置计算 BRIEF 描述子
    descriptor->compute(img_1,keypoints_1,descriptors_1);
    descriptor->compute(img_2,keypoints_2,descriptors_2);

    // --第三步:对两幅图像中的BRIEF描述子进行匹配，使用Hamming距离
    vector<DMatch> match;
    matcher->match(descriptors_1,descriptors_2,match);

    // --第四步：匹配点对筛选
    double min_dist = 10000, max_dist = 0;

    // 找出所有匹配之间的最小距离和最大距离，即是最相似的和最不相似的两组点间的距离
    for (int i = 0; i < descriptors_1.rows; i++)
    {
        double dist = match[i].distance;
        if (dist < min_dist) min_dist = dist;
        if (dist > max_dist) max_dist = dist;
    }

    // 当描述子之间的距离大于两倍的最小距离时，即认为匹配有误，但也要为最小距离设置下限
    for (int i = 0; i < descriptors_1.rows; i++)
    {
        if (match[i].distance <= max(2*min_dist,30.0))
        {
            matches.push_back(match[i]);
        }
    }
}

Point2d pixel2cam(const Point2d& p, const Mat& K)
{
    return Point2d
        (
            (p.x - K.at<double>(0,2)) / K.at<double>(0,0), // x = (px-cx)/fx
            (p.y - K.at<double>(1,2)) / K.at<double>(1,1) // y=(py-cy)/fy
        );
}

// g2o_BundleAdjustment 优化
void bundleAdjustment (
    const vector<Point3f> points_3d, // 两幅图像 特征点对中 其一点 根据深度信息得到世界坐标系下的3D点
    const vector<Point2f> points_2d, // 特征点对中的两个2D点
    const Mat& K,
    Mat& R, Mat& t 
)
{
    // 初始化g2o
    typedef g2o::BlockSolver<g2o::BlockSolverTraits<6,3>> Block; // pose 维度为6（优化变量的维度），landmark 维度为3
    Block::LinearSolverType* linearSolver = new g2o::LinearSolverCSparse<Block::PoseMatrixType>(); // 线性方程求解器
    Block* solver_ptr = new Block(linearSolver); // 矩阵块求解器
    g2o::OptimizationAlgorithmLevenberg* solver = new g2o::OptimizationAlgorithmLevenberg(solver_ptr);//LM优化
    g2o::SparseOptimizer optimizer; // 稀疏优化模型
    optimizer.setAlgorithm(solver);//设置求解器

    // 顶点1 vertex 优化变量 相机位姿
    g2o::VertexSE3Expmap* pose = new g2o::VertexSE3Expmap(); // camera pose 旋转矩阵 R 平移矩阵 t 的李代数形式
    Eigen::Matrix3d R_mat; // 3*3 矩阵 
    R_mat << 
            R.at<double>(0,0), R.at<double>(0,1), R.at<double>(0,2),
            R.at<double>(1,0), R.at<double>(1,1), R.at<double>(1,2),
            R.at<double>(2,0), R.at<double>(2,1), R.at<double>(2,2);
    pose->setId(0); //
    pose->estimate(g2o::SE3Quat(R_mat,Eigen::Vector3d(t.at<double>(0,0),t.at<double>(1,0),t.at<double>(2,0))));
    optimizer.addVertex(pose);//添加顶点
    // 顶点2 空间点
    int index = 1;
    for (const Point3f p : points_3d)
    {
        g2o::VertexSBAPointXYZ* point = new g2o::VertexSBAPointXYZ(); // 空间点
        point->setId(index++);
        point->setEstimate(Eigen::Vector3d(p.x,p.y,p.z));
        point->setMarginalized(true);
        optimizer.addVertex(point);
    }

    // 给优化模型添加相机参数！
    g2o::CameraParameters* camera = new g2o::CameraParameters(
        K.at<double>(0,0),Eigen::Vector2d(K.at<double>(0,2),K.at<double>(1,2)),0
    )
    camera->setId(0);
    optimizer.addParameter(camera); // 相机参数 

    // 边 edges 
    index = 1;
    for (const Point2f p : points_2d)
    {
        g2o::EdgeProjectXYZ2UV* edge = new g2o::EdgeProjectXYZ2UV(); // 3D-2D点对，误差项，投影方程
        edge->setId(index);
        edge->setVertex(0,dynamic_cast<g2o::VertexSBAPointXYZ*>(optimizer.vertex(index)));
        edge->setVertex(1,pose);
        edge->setMeasurement(Eigen::Vector2d(p.x,p.y)); // 观测数据
        edge->setParameterId(0,0);
        edge->setInformation(Eigen::Matrix2d::Identity());//误差项系数矩阵  信息矩阵：单位阵协方差矩阵   横坐标误差  和 纵坐标 误差
        optimizer.addEdge(edge);
        index++;
    }

    chrono::steady_clock::time_point t1 = chrono::steady_clock::now();// 计时开始
    optimizer.setVertex(true);
    optimizer.initializeOptimization(); // 初始化
    optimizer.optimize(100); // 优化次数
    chrono::steady_clock::time_point t2 = chrono::steady_clock::now(); // 计时结束
    chrono::duration<double> time_used = chrono::duration_cast<chrono::duration<double>> (t2-t1);
    cout << time_used.count << endl;
    cout << Eigen::Isometry3d(pose->estimate()).matrix() << endl;
}